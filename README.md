# ai-project
Blog: https://medium.com/p/b38eaf3b66vcb/edit

# สรุป
* จากการจำลองระบบแนะนำภาพยนตร์สามารถพิสูจน์ได้ว่าการใช้ Multi-armed Bandit Algorithm สามารถลด Regret ได้ เปอร์เซ็นต์สะสมของการแนะนำของ Bandit ที่ค่าเป็น Liked เหนือกว่าค่าเฉลี่ยของประสิทธิภาพการทดลองใน A/B Testing เราสามารถเปรียบเทียบได้ว่า A/B Testing ให้การแนะนำที่ไม่เหมาะสมจำนวนมากระหว่างการทดสอบ และต้องใช้เวลาในการแก้ไขนาน
การใช้ Bandit Algorithm อาจให้ผลลัพธ์ที่ดีกว่า ทั้งการ Converge ที่รวดเร็วกว่า หรือการทำงานที่ช้าแต่ให้ประสิทธิภาพการประมาลผลที่ดีในระยะยาว ซึ่งขึ้นกับสถานการณ์ และความต้องการจำเพาะในตอนนั้น อย่างไรก็ตาม A/B Testing ยังคงเป็นเครื่องมือที่สามารถนำมาใช้งานได้ เนื่องจาก Bandit Algorithm ลดการใช้งานตัวเลือกที่ด้อยกว่า ทำให้ต้องใช้เวลานานกว่าในการสร้างค่าสถิติที่สำคัญในการทำงานให้ได้ประสิทธิภาพ ซึ่งอาจเป็นข้อพิจารณาที่สำคัญ ท้ายที่สุดแล้วผู้ทำการทดสอบจะต้องเป็นผู้ตัดสินใจว่าจะใช้งาน Algorithm ไหนในสถานการณ์ที่กำหนด
